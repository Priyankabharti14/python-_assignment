{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea8bbeb-7b7c-4117-b96c-1b3d57e888ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your YouTube search query:  extract the url of first five video\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No video URLs found.\n"
     ]
    }
   ],
   "source": [
    "#Q1. Write a python program to extract the video URL of the first five videos.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_youtube_video_urls(search_query):\n",
    "    url = f\"https://www.youtube.com/@PW-Foundation/videos?search_query={search_query}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        video_tags = soup.find_all(\"a\", class_=\"yt-uix-tile-link\")\n",
    "        \n",
    "        video_urls = []\n",
    "        for tag in video_tags[:5]:  \n",
    "            video_url = \"https://www.youtube.com/@PW-Foundation/videos\" + tag[\"href\"]\n",
    "            video_urls.append(video_url)\n",
    "        \n",
    "        return video_urls\n",
    "    else:\n",
    "        print(\"Failed to retrieve the webpage.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "search_query = input(\"Enter your YouTube search query: \")\n",
    "video_urls = get_youtube_video_urls(search_query)\n",
    "\n",
    "if video_urls:\n",
    "    print(\"Video URLs of the first five videos:\")\n",
    "    for url in video_urls:\n",
    "        print(url)\n",
    "else:\n",
    "    print(\"No video URLs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2674505-f349-4840-b9f8-e4d62f625e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your YouTube search query:  extract the thumbnail of the first five video\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No thumbnail URLs found.\n"
     ]
    }
   ],
   "source": [
    "#Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_youtube_thumbnail_urls(search_query):\n",
    "    url = f\"https://www.youtube.com/@PW-Foundation/videos?search_query={search_query}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        thumbnail_tags = soup.find_all(\"img\", class_=\"style-scope yt-img-shadow\")\n",
    "        \n",
    "        thumbnail_urls = []\n",
    "        for tag in thumbnail_tags[:5]:  \n",
    "            thumbnail_url = tag[\"src\"]\n",
    "            thumbnail_urls.append(thumbnail_url)\n",
    "        \n",
    "        return thumbnail_urls\n",
    "    else:\n",
    "        print(\"Failed to retrieve the webpage.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "search_query = input(\"Enter your YouTube search query: \")\n",
    "thumbnail_urls = get_youtube_thumbnail_urls(search_query)\n",
    "\n",
    "if thumbnail_urls:\n",
    "    print(\"Thumbnail URLs of the first five videos:\")\n",
    "    for url in thumbnail_urls:\n",
    "        print(url)\n",
    "else:\n",
    "    print(\"No thumbnail URLs found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d479e6e-5175-435d-9324-169a6d30f371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your YouTube search query:  extract titles of the first five video\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No video titles found.\n"
     ]
    }
   ],
   "source": [
    "#Q3. Write a python program to extract the title of the first five videos.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_youtube_video_titles(search_query):\n",
    "    url = f\"https://www.youtube.com/results?search_query={search_query}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        title_tags = soup.find_all(\"a\", class_=\"yt-uix-tile-link\")\n",
    "        \n",
    "        video_titles = []\n",
    "        for tag in title_tags[:5]:  \n",
    "            video_title = tag.text\n",
    "            video_titles.append(video_title)\n",
    "        \n",
    "        return video_titles\n",
    "    else:\n",
    "        print(\"Failed to retrieve the webpage.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "search_query = input(\"Enter your YouTube search query: \")\n",
    "video_titles = get_youtube_video_titles(search_query)\n",
    "\n",
    "if video_titles:\n",
    "    print(\"Titles of the first five videos:\")\n",
    "    for title in video_titles:\n",
    "        print(title)\n",
    "else:\n",
    "    print(\"No video titles found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef4b2df9-c18f-4695-9b3c-00855ea879a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your YouTube search query:  extract view counts of the first five videos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View counts not available for the first five videos.\n"
     ]
    }
   ],
   "source": [
    "#Q4. Write a python program to extract the number of views of the first five videos.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_youtube_video_views(search_query):\n",
    "    url = f\"https://www.youtube.com/@PW-Foundation/videos?search_query={search_query}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        view_tags = soup.find_all(\"div\", class_=\"yt-lockup-meta-info\")\n",
    "        \n",
    "        view_counts = []\n",
    "        for tag in view_tags[:5]:  # Extract view counts of the first five videos\n",
    "            view_count_tag = tag.find(\"span\", class_=\"yt-view-count-rendered\")\n",
    "            if view_count_tag:\n",
    "                view_count = view_count_tag.text\n",
    "            else:\n",
    "                view_count = \"View count not available\"\n",
    "            view_counts.append(view_count)\n",
    "        \n",
    "        return view_counts\n",
    "    else:\n",
    "        print(\"Failed to retrieve the webpage.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "search_query = input(\"Enter your YouTube search query: \")\n",
    "view_counts = get_youtube_video_views(search_query)\n",
    "\n",
    "if view_counts:\n",
    "    print(\"Number of views of the first five videos:\")\n",
    "    for view_count in view_counts:\n",
    "        print(view_count)\n",
    "else:\n",
    "    print(\"View counts not available for the first five videos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d120092-7ac9-49a7-85a2-4426ed031e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your YouTube search query:  extract upload time of the first videos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload times not available for the first five videos.\n"
     ]
    }
   ],
   "source": [
    "#Q5. Write a python program to extract the time of posting of video for the first five videos.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_youtube_video_upload_times(search_query):\n",
    "    url = f\"https://www.youtube.com/results?search_query={search_query}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        time_tags = soup.find_all(\"span\", class_=\"accessible-description\")\n",
    "        \n",
    "        upload_times = []\n",
    "        for tag in time_tags[:5]:  # Extract upload times of the first five videos\n",
    "            upload_time = tag.text\n",
    "            upload_times.append(upload_time)\n",
    "        \n",
    "        return upload_times\n",
    "    else:\n",
    "        print(\"Failed to retrieve the webpage.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "search_query = input(\"Enter your YouTube search query: \")\n",
    "upload_times = get_youtube_video_upload_times(search_query)\n",
    "\n",
    "if upload_times:\n",
    "    print(\"Upload times of the first five videos:\")\n",
    "    for upload_time in upload_times:\n",
    "        print(upload_time)\n",
    "else:\n",
    "    print(\"Upload times not available for the first five videos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875c373-5790-4a5d-a84d-1ad0739f818b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
